---
talk-title: " Cooperative learning for multiview analysis"
author: "Tony Liang"
course: "BMEG524"
talk-date: "March 18, 2024"
format: revealjs
knitr: 
  opts_chunk: 
    R.options: 
      knitr.table.html.attr: "quarto-disable-processing=true"
---

```{r}
#| echo: false
#| include: false
#| message: false
#| warning: false

# Setup block
library(tidyverse)
library(kableExtra)
library(knitr)

# Params to use
secondary = "#e98a15"
primary = "#2c365e"
tertiary = "#0a8754"
fourth_color = "#a8201a"

## for simplicity
purple = primary
blue = primary
orange = secondary
green = tertiary
red = fourth_color
```

<!--- This looks very ugly TODO: FIX THIS --->

<br>
<br>

::: {.primary .bold .justify-center .f-subheadline .tj .flex}

{{< meta talk-title  >}}

:::

<br>

<br>


::: {.f1 .bold .tc}

<br>


{{< meta author >}} 

<br>

{{< meta course >}}


{{< meta talk-date >}}

::: 



## Multiomics data

Different types of molecular measurements (omics) from common set of samples

:::: {.columns}


<!-- ::: {.column width="10%"}
::: -->

::: {.column width="28%"}

<br>

- Genomics
- Proteomics
- Metabolomics
- And more

:::

::: {.column width="72%"} 
```{r}
#| echo: false
#| label: "fig-fusion"
#| fig-cap: "Multiomics data fusion source"
knitr::include_graphics("assets/fig1-a.png")
```

:::

::::

## Types of fusion strategy


[How to combine usage of different modalities?]{.secondary}


- `Early`


  - Merge multiple modalities into single representation first, then feed to ML model
  - Requires extracted features to be converted to a common format^[@poria2017review]



- `Late`
  
  - Fit model on each individual modality, then predictions of these models are combined into final predictor
  - Allow more flexibility and easier to handle missing modality^[@liu2018learn]


- `Mixing of both perhaps?`

::: {.notes}

- Early fusion, fewer literatures that adopt 
  - The training pipeline is simple as only one model is involved. 
  - It usually requires the features from different modalities to be highly engineered and preprocessed so that they align well or are similar in their semantics.


- Late fusion, more dominant in lit 

- Analogy to LASSO, Ridge or elastic-net

-  as predictions are made separately
:::



## Input data for the algorithm

Takes in data from various modalities mentioned earlier, integrating heterogenous features on common set of observations (say patients)


::: {.callout-note}

# Example

Input from same patients:

- RNA expression
- DNA-methylation measurements

Predict cancer outcomes

:::

::: {.fragment}


1. Both data views potentially have prognostic value
2. Two view share some underlysing relationship with each other

:::


::: {.notes}

- DNA methylation regulates gene expression --> could repress expression tumor suppresor genes  or promote expression of oncogenes

:::


## When would you want to do this analysis?

:::: {.columns}

::: {.fragment .fade-in-then-semi-out .column width="50%"}

- Access to multiple modalities data from [same]{.secondary} biological samples
  <!-- - Specially when they share some underlying relationship in their signals -->

- Making discoveries that are [hidden]{.secondary} in data analyses of single modality
  <!-- - Say, you want to see how RNA expressions can interact with DNA methylation -->

- Achieving more accurate predictions of the outcome variable

:::

::: {.fragment .column width="50%"}

<br>
<br>

```{r}
#| echo: false
#| fig-align: center
cols = c(blue, red, green, orange)
par(mfrow = c(2, 2), bty = "n", ann = FALSE, xaxt = "n", yaxt = "n", 
    family = "serif", mar = c(0, 0, 0, 0), oma = c(0, 2, 2, 0))
library(mvtnorm)
mv <- matrix(c(0, 0, 0, 0, -.5, -.5, -.5, -.5), 4, byrow = TRUE)
va <- matrix(c(.02, .02, .1, .1, .02, .02, .1, .1), 4, byrow = TRUE)

for (i in 1:4) {
  plot(0, 0, ylim = c(-2, 2), xlim = c(-2, 2), pch = 19, cex = 42, 
       col = blue, ann = FALSE, pty = "s")
  points(0, 0, pch = 19, cex = 30, col = "white")
  points(0, 0, pch = 19, cex = 18, col = green)
  points(0, 0, pch = 19, cex = 6, col = orange)
  points(rmvnorm(20, mean = mv[i, ], sigma = diag(va[i, ])), cex = 1, pch = 19)
  switch(i,
    "1" = {
      mtext("low variance", 3, cex = 2)
      mtext("low bias", 2, cex = 2)
    },
    "2" = mtext("high variance", 3, cex = 2),
    "3" = mtext("high bias", 2, cex = 2)
  )
}
```

:::

::::


## Motivation and background 3

::: {.callout-note}

What does it tell you?

:::

Using this algorithm, we could model outcome of interest better by fusing different data views

::: {.fragment}

- Addresses "`fusion`" in data-adaptive manner
- Combines different omics together, they call this "`view`"


:::



## Overview structure of Cooperative Learning
<!-- 
::: {.callout-note}
- What is the theoretical underpinnings of the approach
::: -->

```{r}
#| label: "fig-underpinnig"
#| fig-cap: "Fusion strategies of views"
knitr::include_graphics("assets/fig1-b.png")
```

::: {.notes}

- When $\rho = 0$, it yields early fusion

- When $\rho = 1$, it yields late fusion

:::



## Algorithm 2

::: {.callout-note}
- How does it work?
:::

## What considerations are there when applying it?


::: {.callout-important}

Well we have the algorithm now, but it has sevaral key assumptions

:::

::: {.incremental}

- Requires omics data from same providers --> [Might not always be feasible]{.fourth-colour}
- Runtime complexity is high due to its iterative nature --> [Higher computation costs]{.fourth-colour}
<!-- - Works best if the omics itself are related each other -->
- Extendable to both regression and classification --> [Careful of asking right question]{.fourth-colour}

:::

::: {.notes}

- More about what if input data not good later

:::


## Evaluation of algorithm by metrics

Due it supervising nature, one could verify its performance through various metrics by task performed:

- Classification
  - A
  - B

- Regression
  - MSE
  - MAE

<!-- ::: {.callout-note}
- How can you determine whether it worked?
::: -->

## What happens if data quality is not good?

When the views are not correlated, this could be very [bad]{.secondary}^[Appendix Fig S3 from @ding2022cooperative]

```{r}
#| echo: false
#| fig-cap: "Both X, Z contains signal, no correlation"
knitr::include_graphics("assets/app_s3c-a.png")
```

## What happens if data quality is not good?

When the views are not correlated, this could be very [bad]{.secondary}^[Appendix Fig S3 from @ding2022cooperative]

```{r}
#| echo: false
#| layout-ncol: 2
#| fig-cap: 
#| - "Both X, Z contains signal, no correlation"
#| - "Only X contains signal"
knitr::include_graphics("assets/app_s3c-a.png")
knitr::include_graphics("assets/app_s3c-c.png")
```

## What happens if data quality is not good?

When the views are not correlated, this could be very [bad]{.secondary}^[Appendix Fig S3 from @ding2022cooperative]

```{r}
#| echo: false
#| layout-ncol: 3
#| fig-cap: 
#| - "Both X, Z contains signal"
#| - "X with more signal than Z"
#| - "Only X contains signal"
knitr::include_graphics("assets/app_s3c-a.png")
knitr::include_graphics("assets/app_s3c-b.png")
knitr::include_graphics("assets/app_s3c-c.png")
```

## Case Study on Labor Onset Prediction {.smaller}

<!-- ::: {.callout-note}
- Are there special analysis considerations?
::: -->

Authors performed their algorithm on a labor dataset from another study^[@stelzer2021integrated]

:::: {.columns}

::: {.column width="37%"}

- Measured proteome and metabolome from $53$ patients of a longitudinal study

- [Predict time (days) to spontaneous labor]{.fourth-colour}

- The other study used LASSO^[@tibshirani1996regression] for each omics individually (like in late fussion)

:::

::: {.column width="3%"} 

:::

::: {.fragment .column width="60%"}

```{r}
#| echo: false
#| label: "tbl-labor"
#| tbl-cap-location: bottom
#| tbl-cap: "Multiomics studies on labor-onset prediction^[@ding2022cooperative]"
# Then the kable
sub_header <- c("", "Mean", "SD", "Mean", "SD", "Mean")
data <- read.csv("data/labor.csv")
# The kable goes here
data %>% 
  kable(align = "c", 
        col.names = sub_header,
        table.attr = "quarto-disable-processing=true"
        ) %>%
  add_header_above(c("Methods", "Test MSE" = 2, "Relative to early fusion" = 2, "Numbers of features selected")) %>% 
  row_spec(5, bold = T, color="#a8201a") %>%
  kable_styling(c("striped", "bordered"), full_width = FALSE)
```

:::

::::



::: {.notes}

- 1,322 proteins, and the metabolomics data contained measurements for 3,529 metabolites

- split the dataset of 53 patients into training and test sets of 40 and 13 patients, respectively

- from blood samples, during the last $120$ day of pregnancy

- Units are days, so MSE need to take square root here to explain

:::


## Analysis 2

::: {.callout-note}
- Controlling for sources of bias
:::

## Analysis 3

::: {.callout-note}
- Insights into analysis?
:::

<!-- ```{r}
r1 <- c("Separate Proteomics", 475.51, 80.89, 69.14, 81.44, 26)
r2 <- c("Separate Metabolomics", 381.13, 36.88, -25.24, 30.91, 11)
r3 <- c("Early fusion", 406.37, )
``` -->

## Analysis 4

::: {.callout-note}
- What is the biological interpretation?
:::


## {#end}

<br>
<br>

<br>
<br>

::: {.closing}

Questions?

:::



## {#reference}