---
talk-title: " Cooperative learning for multiview analysis"
author: "Tony Liang"
course: "BMEG524"
talk-date: "March 18, 2024"
format: revealjs
knitr: 
  opts_chunk: 
    R.options: 
      knitr.table.html.attr: "quarto-disable-processing=true"
---

```{r}
#| echo: false
#| include: false
#| message: false
#| warning: false

# Setup block
library(tidyverse)
library(kableExtra)
library(knitr)

# Params to use
secondary = "#e98a15"
primary = "#2c365e"
tertiary = "#0a8754"
fourth_color = "#a8201a"

## for simplicity
purple = primary
blue = primary
orange = secondary
green = tertiary
red = fourth_color
```

<!--- This looks very ugly TODO: FIX THIS --->

<br>
<br>

::: {.primary .bold .justify-center .f-subheadline .tj .flex}

{{< meta talk-title  >}}

:::

<br>

<br>


::: {.f1 .bold .tc}

<br>


{{< meta author >}} 

<br>

{{< meta course >}}


{{< meta talk-date >}}

::: 



## Multiomics data

Different types of molecular measurements (omics) from common set of samples

:::: {.columns}


<!-- ::: {.column width="10%"}
::: -->

::: {.column width="28%"}

<br>

- Genomics
- Proteomics
- Metabolomics
- And more

:::

::: {.column width="72%"} 
```{r}
#| echo: false
#| label: "fig-fusion"
#| fig-cap: "Multiomics data fusion source^[Adopted fig 1A from @ding2022cooperative]"
knitr::include_graphics("assets/fig1-a.png")
```

:::

::::

## Types of fusion strategy


[How to combine usage of different modalities?]{.secondary}


::: {.fragment}

- `Early`

  - Merge multiple modalities into single representation first, then feed to ML model
  - Requires extracted features to be converted to a common format^[@poria2017review]

:::

::: {.fragment}

- `Late`
  
  - Fit model on each individual modality, then predictions of these models are combined into final predictor
  - Allow more flexibility and easier to handle missing modality^[@liu2018learn]

:::


::: {.notes}

- Early fusion, fewer literatures that adopt 
  - The training pipeline is simple as only one model is involved. 
  - It usually requires the features from different modalities to be highly engineered and preprocessed so that they align well or are similar in their semantics.


- Late fusion, more dominant in lit 

- Analogy to LASSO, Ridge or elastic-net

-  as predictions are made separately
:::



## Input data for the algorithm

Takes in data from various modalities mentioned earlier, integrating heterogenous features on common set of observations (say patients)


::: {.callout-note}

# Example

Input from same patients:

- RNA expression
- DNA-methylation measurements

Predict cancer outcomes

:::

::: {.fragment}


1. Both data views potentially have prognostic value
2. Two view share some underlysing relationship with each other

:::


::: {.notes}

- DNA methylation regulates gene expression --> could repress expression tumor suppresor genes  or promote expression of oncogenes

:::


## When would you want to do this analysis?

:::: {.columns}

::: {.fragment .fade-in-then-semi-out .column width="50%"}

- Access to multiple modalities data from [same]{.secondary} biological samples
  <!-- - Specially when they share some underlying relationship in their signals -->

- Making discoveries that are [hidden]{.secondary} in data analyses of single modality
  <!-- - Say, you want to see how RNA expressions can interact with DNA methylation -->

- Achieving more accurate predictions of the outcome variable

:::

::: {.fragment .column width="50%"}

<br>
<br>

```{r}
#| echo: false
#| fig-align: center
cols = c(blue, red, green, orange)
par(mfrow = c(2, 2), bty = "n", ann = FALSE, xaxt = "n", yaxt = "n", 
    family = "serif", mar = c(0, 0, 0, 0), oma = c(0, 2, 2, 0))
library(mvtnorm)
mv <- matrix(c(0, 0, 0, 0, -.5, -.5, -.5, -.5), 4, byrow = TRUE)
va <- matrix(c(.02, .02, .1, .1, .02, .02, .1, .1), 4, byrow = TRUE)

for (i in 1:4) {
  plot(0, 0, ylim = c(-2, 2), xlim = c(-2, 2), pch = 19, cex = 42, 
       col = blue, ann = FALSE, pty = "s")
  points(0, 0, pch = 19, cex = 30, col = "white")
  points(0, 0, pch = 19, cex = 18, col = green)
  points(0, 0, pch = 19, cex = 6, col = orange)
  points(rmvnorm(20, mean = mv[i, ], sigma = diag(va[i, ])), cex = 1, pch = 19)
  switch(i,
    "1" = {
      mtext("low variance", 3, cex = 2)
      mtext("low bias", 2, cex = 2)
    },
    "2" = mtext("high variance", 3, cex = 2),
    "3" = mtext("high bias", 2, cex = 2)
  )
}
```

:::

::::

## Overview structure of Cooperative Learning {.smaller}
<!-- 
::: {.callout-note}
- What is the theoretical underpinnings of the approach
::: -->



```{r}
#| label: "fig-underpinnig"
#| fig-cap: "Fusion strategies of views"
knitr::include_graphics("assets/fig1-b.png")
```

::: {.fragment}

- Addresses "`fusion`" in data-adaptive manner
- Combines different omics together, they call this "`view`"

:::



::: {.notes}

- What means data-adaptive manner?

- When $\rho = 0$, it yields early fusion

- When $\rho = 1$, it yields late fusion

:::



## Little bit of math {.smaller}

<!-- ::: {.callout-note}
- How does it work?
::: -->

From the original paper^[@ding2022cooperative], authors stated below:

::: {.fragment .fade-in-then-semi-out}

For [two]{.secondary} data views (main example from paper)

$$\text{min} \quad E[\frac{1}{2} (y - f_{X}(X) - f_{Z}(Z))^2 + \frac{\rho}{2} (f_{X}(X) - f_{Z}(Z))^2]$${#eq-2d}

:::

::: {.fragment .fade-in-then-semi-out}

For [more than two]{.secondary} data views (generalized version of above)

$$\text{min} \quad E[\frac{1}{2} (y - \sum\limits_{m=1}^M f_{X_{m}}(X_{m}))^2 + \frac{\rho}{2} \sum\limits_{m < m'} (f_{X_{m}}(X_{m}) - f_{X_{m'}}(X_{m'}))^2]$${#eq-rn}

:::

::: {.fragment}

Or `simplified` to the following with L1-regularization:

$$J(\boldsymbol{\theta}_1, \boldsymbol{\theta}_2, \ldots, \boldsymbol{\theta}_M) = \frac{1}{2} \left\| \boldsymbol{y} - \sum\limits_{m=1}^{M} \boldsymbol{X}_m \boldsymbol{\theta}_m \right\|_2^2 + \frac{\rho}{2} \sum\limits_{m < m'} \left\| \left( \boldsymbol{X}_m \boldsymbol{\theta}_m - \boldsymbol{X}_{m'} \boldsymbol{\theta}_{m'} \right) \right\|_2^2 + \sum\limits_{m=1}^{M} \lambda_m \left\| \boldsymbol{\theta}_m \right\|_1$${#eq-jac}

where $\rho$ is hyperparameter tunable by cross validation (CV), s.t. $\rho \in [0, 1]$, and $\theta_m$ are weights of each view that minimizes the objective.

:::

::: {.notes}

- First term is squared error
- Second term is agreement penalty

- These theta are weights, and they have a good way of solving them through minimizing each lasso problem 

- By varying the weight of the agreement penalty, cooperative learning yields a continuum of solutions that include early and late fusion:

- adaptive strategy for optimizing over λx and λz. We call this “adaptive cooperative learning” in our studies.
- With a common λ, the objective becomes like the Jacobian above                                                                        
- They solve this by iteratively updating the $\theta$ by fixing one and optimizing others and relying on that the problem itself are convex (meaning computationally solvable)

- Convexity ensures that all local optima are global optima. 

:::


## What considerations are there when applying it?


::: {.callout-important}

Well we have the algorithm now, but it has sevaral key assumptions

:::

::: {.incremental}

- Requires omics data from same providers --> [Might not always be feasible]{.fourth-colour}
- Runtime complexity is high due to its iterative nature --> [Higher computation costs]{.fourth-colour}
- Correlation between views --> [Might have to access other views]{.fourth-colour}
<!-- - Works best if the omics itself are related each other -->
- Extendable to both regression and classification --> [Careful of asking right question]{.fourth-colour}

:::

::: {.notes}

- More about what if input data not good later

:::


## Evaluation of algorithm by metrics

Due to its `supervising` nature, one could verify its performance through various metrics by task performed:

- [Classification]{.secondary}
  - Receiver operating characteristic (ROC) curve
  - Accuracy 
  - F1 score

- [Regression]{.secondary}
  - Mean squared error (MSE)
  - Mean absolute error (MAE)
  - Root mean squared error (RMSE), although could be derived from MSE


<!-- ::: {.callout-note}
- How can you determine whether it worked?
::: -->

::: {.notes}

- ROC curve balances true positive rate and false positive rate
- F1 score is weighted average between precision and recall
:::

## What happens if data quality is not good?

When the views are not correlated or no signal, this could be very [bad]{.secondary}^[Appendix Fig S3 from @ding2022cooperative]

```{r}
#| echo: false
#| fig-cap: "Both X, Z contains signal, no correlation"
knitr::include_graphics("assets/app_s3c-a.png")
```

## What happens if data quality is not good?

When the views are not correlated or no signal, this could be very [bad]{.secondary}^[Appendix Fig S3 from @ding2022cooperative]

```{r}
#| echo: false
#| layout-ncol: 2
#| fig-cap: 
#| - "Both X, Z contains signal, no correlation"
#| - "Only X contains signal"
knitr::include_graphics("assets/app_s3c-a.png")
knitr::include_graphics("assets/app_s3c-c.png")
```

## What happens if data quality is not good?

When the views are not correlated or no signal, this could be very [bad]{.secondary}^[Appendix Fig S3 from @ding2022cooperative]

```{r}
#| echo: false
#| layout-ncol: 3
#| fig-cap: 
#| - "Both X, Z contains signal"
#| - "X with more signal than Z"
#| - "Only X contains signal"
knitr::include_graphics("assets/app_s3c-a.png")
knitr::include_graphics("assets/app_s3c-b.png")
knitr::include_graphics("assets/app_s3c-c.png")
```

## Case Study on Labor Onset Prediction {.smaller}

<!-- ::: {.callout-note}
- Are there special analysis considerations?
::: -->

Authors performed their algorithm on a labor dataset from another study^[@stelzer2021integrated]

:::: {.columns}

::: {.column width="37%"}

- Measured proteome and metabolome from $53$ patients of a longitudinal study

- [Predict time (days) to spontaneous labor]{.fourth-colour}

- The other study used LASSO^[@tibshirani1996regression] for each omics individually (like in late fussion)

:::

::: {.column width="3%"} 

:::

::: {.fragment .column width="60%"}

```{r}
#| echo: false
#| label: "tbl-labor"
#| tbl-cap-location: bottom
#| tbl-cap: "Multiomics studies on labor-onset prediction^[@ding2022cooperative]"
# Then the kable
sub_header <- c("", "Mean", "SD", "Mean", "SD", "Mean")
data <- read.csv("data/labor.csv")
# The kable goes here
data %>% 
  kable(align = "c", 
        col.names = sub_header,
        table.attr = "quarto-disable-processing=true"
        ) %>%
  add_header_above(c("Methods", "Test MSE" = 2, "Relative to early fusion" = 2, "Numbers of features selected")) %>% 
  row_spec(5, bold = T, color="#a8201a") %>%
  kable_styling(c("striped", "bordered"), full_width = FALSE)
```

:::

::::



::: {.notes}

- 1,322 proteins, and the metabolomics data contained measurements for 3,529 metabolites

- split the dataset of 53 patients into training and test sets of 40 and 13 patients, respectively

- from blood samples, during the last $120$ day of pregnancy

- Units are days, so MSE need to take square root here to explain

:::


## Case Study on Labor Onset Prediction

<!-- ::: {.callout-note}
- Controlling for sources of bias
::: -->

```{r}
#| echo: false
#| label: "fig-labor-pred"
#| fig-cap: " Distribution of time to delivery and predicted versus true time to delivery for training and test samples^[Fig S9 from @ding2022cooperative]"
knitr::include_graphics("assets/predictions_labor.png")
```


## Cohort Study on COVID-19 {.smaller}

Another study^[@er2023multimodal] that used Cooperative Learning combined with other ML and NLP techniques to predict the clinical outcome of COVID-19 patients.


:::: {.columns}


::: {.incremental .column width="43%"}


- Predict ICU hospitalization (`binary` outcome)
- $149$ patients, $63$ were admitted in ICU
  - Only $89$ patients in model training
- Possible [overfitting]{.secondary} due to class imbalance
- [Stratified]{.secondary} and [nested]{.secondary} CV framework for estimating performances and controlling bias
  - Also, repeated the CV procedure $30$ times

:::

::: {.column width="57%"}

```{r}
#| echo: false
#| label: "fig-covid"
#| fig-cap: "Number of patients in the cohort with different  modalities"
knitr::include_graphics("assets/covid19_pat.png")
```

:::

::::

::: {.notes}

- Used combinations of NLP word2vec for viral embedding, and mixxed with imaging stuff to get these predictions

:::

## Cohort Study on COVID-19

<!-- ::: {.callout-note}
- What is the biological interpretation?
::: -->

The algorithm identified key biomarkers that played bigger role in determining ICU hospitalization of patients and relationship between modalities:

- Serum biomarkers mainly found to be correlated with radiomics features related to the distribution of voxel intensities.

- LDH, ESR, CRP, albumin, and total bilirubin were the selected serum biomarkers

<!-- - age, chronic disease, and CCI were the clinical variables of the CLRW model. -->

::: {.notes}

- Serum biomarker: substances changing quantitatively in the serum during tumor development. 
  - Classically, a marker is synthesized by the tumor and released into circulation or expressed at the cell surface in large quantity by malignant cells

:::


## {#end}

<br>
<br>

<br>
<br>

::: {.closing}

Questions?

:::



## {#reference}